{
  "hash": "86d3922bcfe4688e9addf0c3450d9fed",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Multiple Linear Regression\"\ncode-fold: false\nnumber-depth: 2\n---\n\n\n\n\n\n::: {.callout-tip appearance=\"simple\"}\n## Do it yourself with R\n\nCopy the script [MultipleLinarRegression.R](https://github.com/U-Shift/MQAT/blob/main/code/classroom/MultipleLinarRegression.R) and paste it in your session.\\\nRun each line using `CTRL` + `ENTER`\n:::\n\n::: callout-caution\n## Your task\n\nEstimate a linear regression model that predicts the car percentage per district.\n:::\n\n## Load packages\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse) # Pack of most used libraries for data science\nlibrary(skimr) # summary of the data\nlibrary(DataExplorer) # exploratory data analysis\nlibrary(corrplot) # correlation plots\n\nlibrary(car) # Testing autocorrelation (Durbin Watson)\nlibrary(olsrr) # Testing multicollinearity (VIF, TOL, etc.)\n```\n:::\n\n\n\n\n\n## Dataset\n\nThe database used in this example is a treated database from the Mobility Survey for the metropolitan areas of Lisbon in 2018 [@IMOB].\n\nIncluded **variables**:\n\n-   `Origin_dicofre16` - Code of Freguesia (district) as set by INE after 2016 (Distrito + Concelho + Freguesia), for trip origin\n-   `Total` - number of trips with origin at each district\n-   `Walk` - number of walking trips\n-   `Bike` - number of bike trips\n-   `Car` - number of car trips. Includes taxi and motorcycle.\n-   `PTransit` - number of Public Transit trips\n-   `Other` - number of other trips (truck, van, tractor, aviation)\n-   `Distance` - average trip distance (km)\n-   `Duration` - average trip duration (minutes)\n-   `Car_perc` - percentage of car trips\n-   `N_INDIVIDUOS` - number of residents [@INEcensus]\n-   `Male_perc` - percentage of male residents [@INEcensus]\n-   `IncomeHH` - average household income\n-   `Nvehicles` - average number of car/motorcycle vehicles in the household\n-   `DrivingLic` - percentage of car driving licence holders\n-   `CarParkFree_Work` - percentage of respondents with free car parking at the work location\n-   `PTpass` - percentage of public transit monthly pass holders\n-   `internal` - binary variable (factor). `Yes`: trip with same TAZ origin and destination, `No`: trips with different destination\n-   `Lisboa` - binary variable (factor). `Yes`: the district is part of Lisbon municipality, `No`: otherwise\n-   `Area_km2` - area of in `Origin_dicofre16`, in km^2^\n\n### Import dataset\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata = readRDS(\"../data/IMOBmodel.Rds\")\ndata_continuous = data |> select(-Origin_dicofre16, -internal, -Lisboa) # Exclude categorical variables\n```\n:::\n\n\n\n\n\nShow summary statistics\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nskim(data)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in attr(x, \"align\"): 'xfun::attr()' is deprecated.\nUse 'xfun::attr2()' instead.\nSee help(\"Deprecated\")\nWarning in attr(x, \"align\"): 'xfun::attr()' is deprecated.\nUse 'xfun::attr2()' instead.\nSee help(\"Deprecated\")\nWarning in attr(x, \"align\"): 'xfun::attr()' is deprecated.\nUse 'xfun::attr2()' instead.\nSee help(\"Deprecated\")\nWarning in attr(x, \"align\"): 'xfun::attr()' is deprecated.\nUse 'xfun::attr2()' instead.\nSee help(\"Deprecated\")\n```\n\n\n:::\n\n::: {.cell-output-display}\n\nTable: Data summary\n\n|                         |     |\n|:------------------------|:----|\n|Name                     |data |\n|Number of rows           |236  |\n|Number of columns        |20   |\n|_______________________  |     |\n|Column type frequency:   |     |\n|character                |1    |\n|factor                   |2    |\n|numeric                  |17   |\n|________________________ |     |\n|Group variables          |None |\n\n\n**Variable type: character**\n\n|skim_variable    | n_missing| complete_rate| min| max| empty| n_unique| whitespace|\n|:----------------|---------:|-------------:|---:|---:|-----:|--------:|----------:|\n|Origin_dicofre16 |         0|             1|   6|   6|     0|      118|          0|\n\n\n**Variable type: factor**\n\n|skim_variable | n_missing| complete_rate|ordered | n_unique|top_counts        |\n|:-------------|---------:|-------------:|:-------|--------:|:-----------------|\n|internal      |         0|             1|FALSE   |        2|Yes: 118, No: 118 |\n|Lisboa        |         0|             1|FALSE   |        2|No: 188, Yes: 48  |\n\n\n**Variable type: numeric**\n\n|skim_variable    | n_missing| complete_rate|     mean|       sd|      p0|      p25|      p50|      p75|      p100|hist  |\n|:----------------|---------:|-------------:|--------:|--------:|-------:|--------:|--------:|--------:|---------:|:-----|\n|Total            |         0|             1| 22457.00| 19084.45|  361.00|  5917.75| 17474.00| 33377.50| 112186.00|▇▃▂▁▁ |\n|Walk             |         0|             1|  5383.44|  6224.84|    0.00|   763.25|  3125.00|  8298.50|  32646.00|▇▂▁▁▁ |\n|Bike             |         0|             1|   107.03|   248.65|    0.00|     0.00|    13.50|    98.75|   2040.00|▇▁▁▁▁ |\n|Car              |         0|             1| 13289.24| 12351.61|    0.00|  3243.00|  9008.00| 21248.75|  52631.00|▇▃▂▁▁ |\n|PTransit         |         0|             1|  3473.79|  5467.82|    0.00|   249.00|  1057.00|  4853.00|  41672.00|▇▁▁▁▁ |\n|Other            |         0|             1|   203.45|   336.04|    0.00|     2.00|    44.00|   281.50|   2391.00|▇▁▁▁▁ |\n|Distance         |         0|             1|    11.14|     2.66|    6.84|     9.54|    10.32|    12.10|     22.66|▇▇▂▁▁ |\n|Duration         |         0|             1|    25.42|     3.91|   16.30|    23.00|    24.70|    27.73|     37.42|▁▇▆▂▁ |\n|Car_perc         |         0|             1|    59.00|    21.56|    0.00|    45.40|    62.62|    75.72|     99.27|▁▃▆▇▅ |\n|N_INDIVIDUOS     |         0|             1| 24323.80| 16438.04| 1566.00| 11060.00| 20855.00| 36079.00|  68649.00|▇▆▅▃▁ |\n|Male_perc        |         0|             1|    47.54|     1.57|   44.61|    46.58|    47.50|    48.29|     55.94|▅▇▂▁▁ |\n|IncomeHH         |         0|             1|  1732.55|   453.11|  884.46|  1417.76|  1594.73|  1953.50|   3462.32|▃▇▃▁▁ |\n|Nvehicles        |         0|             1|     1.53|     0.24|    1.02|     1.35|     1.54|     1.67|      2.42|▃▇▆▂▁ |\n|DrivingLic       |         0|             1|    62.50|     8.12|   37.04|    57.67|    63.00|    68.84|     80.79|▁▂▇▇▂ |\n|CarParkFree_Work |         0|             1|    49.30|    14.30|    5.47|    40.39|    50.51|    57.92|     87.60|▁▃▇▇▁ |\n|PTpass           |         0|             1|    23.82|    12.87|    0.00|    13.41|    22.72|    32.94|     60.45|▅▇▇▂▁ |\n|Area_km2         |         0|             1|    25.55|    42.58|    1.49|     5.04|    11.60|    28.51|    282.13|▇▁▁▁▁ |\n\n\n:::\n:::\n\n\n\n\n\nThe dependent variable is continuous.\n\n## Check the assumptions\n\nBefore running the model, you need to check if the assumptions are met.\n\n1.  The dependent variable is normally distributed\n2.  Linear relationship between the dependent variable and the independent variables\n3.  No multicollinearity between independent variables (or only very little)\n4.  The observations are independent\n5.  Constant Variance (Assumption of Homoscedasticity)\n6.  Residuals are normally distributed\n\n## Assumption 1: Normal distribution\n\nThe Dependent Variable is be normally distributed.\n\nCheck the histogram of `Car_perc`:\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhist(data$Car_perc)\n```\n\n::: {.cell-output-display}\n![](linear-regression_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\n\n\n\nIf the sample is small (\\< 50 observations), we use **Shapiro-Wilk** test:\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nshapiro.test(data$Car_perc)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tShapiro-Wilk normality test\n\ndata:  data$Car_perc\nW = 0.97284, p-value = 0.0001709\n```\n\n\n:::\n:::\n\n\n\n\n\nIf not, use the **Kolmogorov-Smirnov** test:\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nks.test(\n  data$Car_perc,\n  \"pnorm\",\n  mean = mean(data$Car_perc),\n  sd = sd(data$Car_perc)\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tAsymptotic one-sample Kolmogorov-Smirnov test\n\ndata:  data$Car_perc\nD = 0.072477, p-value = 0.1675\nalternative hypothesis: two-sided\n```\n\n\n:::\n:::\n\n\n\n\n\nThe null hypothesis for both tests is that the distribution is normal.\nTherefore, for the distribution to be normal, the pvalue must be **\\> 0.05** and the null hypothesis is not rejected.\nFrom the output obtained we can assume normality.\n\n## Assumption 2: Linear relationship\n\nThere is a linear relationship between dependent variable (DV) and independent variables (IV).\n\nWe can check this assumption by plotting scatterplots of the DV against each IV:\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(x = data$Car_perc, y = data$Total, xlab = \"Car_perc (%)\", ylab = \"Total (number of trips)\")  \nplot(x = data$Car_perc, y = data$Walk, xlab = \"Car_perc\", ylab = \"Walk\")  \nplot(x = data$Car_perc, y = data$Bike, xlab = \"Car_perc\", ylab = \"Bike\")  \nplot(x = data$Car_perc, y = data$Car, xlab = \"Car_perc\", ylab = \"Car\")  \nplot(x = data$Car_perc, y = data$PTransit, xlab = \"Car_perc\", ylab = \"PTransit\")\nplot(x = data$Car_perc, y = data$Other, xlab = \"Car_perc\", ylab = \"Other\")\nplot(x = data$Car_perc, y = data$Distance, xlab = \"Car_perc\", ylab = \"Distance\")\nplot(x = data$Car_perc, y = data$Duration, xlab = \"Car_perc\", ylab = \"Duration\")\nplot(x = data$Car_perc, y = data$N_INDIVIDUOS, xlab = \"Car_perc\", ylab = \"N_INDIVIDUOS\")\nplot(x = data$Car_perc, y = data$Male_perc, xlab = \"Car_perc\", ylab = \"Male_perc\")\nplot(x = data$Car_perc, y = data$IncomeHH, xlab = \"Car_perc\", ylab = \"IncomeHH\")\nplot(x = data$Car_perc, y = data$Nvehicles, xlab = \"Car_perc\", ylab = \"Nvehicles\")\nplot(x = data$Car_perc, y = data$DrivingLic, xlab = \"Car_perc\", ylab = \"Driving License\")\nplot(x = data$Car_perc, y = data$CarParkFree_Work, xlab = \"Car_perc\", ylab = \"Free car parking at work\")\nplot(x = data$Car_perc, y = data$PTpass, xlab = \"Car_perc\", ylab = \"PTpass\")\nplot(x = data$Car_perc, y = data$internal, xlab = \"Car_perc\", ylab = \"internal trips\")\nplot(x = data$Car_perc, y = data$Lisboa, xlab = \"Car_perc\", ylab = \"Lisboa\")\nplot(x = data$Car_perc, y = data$Area_km2, xlab = \"Car_perc\", ylab = \"Area_km2\")\n```\n:::\n\n\n\n\n\nOr you can make a pairwise scatterplot matrix, that compares every variable with each other:\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# pairs(data_continuous, pch = 19, lower.panel = NULL) # we have too many variables, let's split the plots\npairs(data_continuous[,1:6], pch = 19, lower.panel = NULL)\n```\n\n::: {.cell-output-display}\n![](linear-regression_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n\n```{.r .cell-code}\npairs(data_continuous[,7:12], pch = 19, lower.panel = NULL)\n```\n\n::: {.cell-output-display}\n![](linear-regression_files/figure-html/unnamed-chunk-8-2.png){width=672}\n:::\n\n```{.r .cell-code}\npairs(data_continuous[,13:17], pch = 19, lower.panel = NULL)\n```\n\n::: {.cell-output-display}\n![](linear-regression_files/figure-html/unnamed-chunk-8-3.png){width=672}\n:::\n:::\n\n\n\n\n\n## Assumption 3: No multicollinearity\n\nCheck the [correlation plot](eda.qmd#correlations) before choosing the variables.\n\n### Declare the model\n\n::: {.callout-tip appearance=\"simple\"}\nUse `CTRL` + `SHIFT` + `C` to comment/uncomment lines (variables)\n:::\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# names(data) # to see the names of the variables\n\nmodel = lm(\n  Car_perc ~ Total +\n    Walk +\n    Bike +\n    Car +\n    PTransit +\n    Other +\n    Distance + \n    Duration + \n    N_INDIVIDUOS + \n    Male_perc + \n    IncomeHH + \n    Nvehicles + \n    DrivingLic + \n    CarParkFree_Work + \n    PTpass + \n    internal + \n    Lisboa + \n    Area_km2,\n  data = data\n)\n\nsummary(model)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = Car_perc ~ Total + Walk + Bike + Car + PTransit + \n    Other + Distance + Duration + N_INDIVIDUOS + Male_perc + \n    IncomeHH + Nvehicles + DrivingLic + CarParkFree_Work + PTpass + \n    internal + Lisboa + Area_km2, data = data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-37.952  -4.907  -0.232   5.305  39.157 \n\nCoefficients:\n                   Estimate Std. Error t value Pr(>|t|)    \n(Intercept)       4.047e+00  3.192e+01   0.127  0.89923    \nTotal             1.633e-01  3.671e-01   0.445  0.65700    \nWalk             -1.640e-01  3.671e-01  -0.447  0.65552    \nBike             -1.614e-01  3.669e-01  -0.440  0.66044    \nCar              -1.627e-01  3.671e-01  -0.443  0.65806    \nPTransit         -1.640e-01  3.672e-01  -0.447  0.65552    \nOther            -1.622e-01  3.671e-01  -0.442  0.65897    \nDistance          6.004e-01  3.629e-01   1.654  0.09948 .  \nDuration         -3.244e-01  3.325e-01  -0.976  0.33032    \nN_INDIVIDUOS     -6.627e-05  8.876e-05  -0.747  0.45612    \nMale_perc         2.723e-01  6.151e-01   0.443  0.65849    \nIncomeHH         -5.218e-04  2.199e-03  -0.237  0.81264    \nNvehicles         7.301e+00  3.959e+00   1.844  0.06650 .  \nDrivingLic        2.910e-01  1.161e-01   2.506  0.01294 *  \nCarParkFree_Work  1.943e-01  7.882e-02   2.465  0.01449 *  \nPTpass           -8.254e-02  9.989e-02  -0.826  0.40956    \ninternalNo        1.962e+01  2.136e+00   9.182  < 2e-16 ***\nLisboaYes        -9.647e+00  3.182e+00  -3.031  0.00273 ** \nArea_km2          1.689e-02  1.860e-02   0.908  0.36486    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 10.59 on 217 degrees of freedom\nMultiple R-squared:  0.7772,\tAdjusted R-squared:  0.7587 \nF-statistic: 42.06 on 18 and 217 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n:::\n\n\n\n\n\n### Assessing the model\n\n1.  First check the **pvalue** and the **F statistics** of the model to see if there is any statistical relation between the dependent variable and the independent variables.\n    If pvalue \\< 0.05 and the F statistics \\> Fcritical = 2.39, then the model is statistically acceptable.\n\n2.  The **R-square** and **Adjusted R-square** evaluate the amount of variance that is explained by the model.\n    The difference between one and another is that the R-square does not consider the number of variables.\n    If you increase the number of variables in the model, the R-square will tend to increase which can lead to overfitting.\n    On the other hand, the Adjusted R-square adjust to the number of independent variables.\n\n3.  Take a look at the **t-value** and the Pr(\\>\\|t\\|).\n    If the t-value \\> 1.96 or Pr(\\>\\|t\\|) \\< 0.05, then the IV is statistically significant to the model.\n\n4.  To analyse the **estimates** of the variables, you should first check the **signal** and assess if the independent variable has a direct or inverse relationship with the dependent variable.\n    It is only possible to evaluate the **magnitude** of the estimate if all variables are continuous and standardized or by calculating the elasticities.\n    Do not forget to access the **Intercept**...\n\nWe can see from the output that the R-squared value for the model (with ALL variables) is **0.7772**.\nWe can also see that the overall F-statistic is **42.06** and the corresponding p-value is **\\<2.2e-16**, which indicates that the overall regression model is significant.\nAlso, the predictor variables `DrivingLic` and `CarParkFree_Work`, `internal(No)` and `Lisboa(Yes)` are statistically significant at the 0.05 significance level.\n\n::: {.callout-tip appearance=\"simple\"}\n### Your turn\n\nNow try to remove some variables from the model and assess it again.\nElaborate a justification to exclude those variables.\n:::\n\n### Calculate the Variance Inflation Factor (VIF)\n\nWe use the `vif()` function from the car package to calculate the VIF for each predictor variable in the model:\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncar::vif(model)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n           Total             Walk             Bike              Car \n    1.028324e+08     1.094004e+07     1.743544e+04     4.307486e+07 \n        PTransit            Other         Distance         Duration \n    8.443136e+06     3.186972e+04     1.957062e+00     3.544018e+00 \n    N_INDIVIDUOS        Male_perc         IncomeHH        Nvehicles \n    4.459671e+00     1.961472e+00     2.079348e+00     1.882275e+00 \n      DrivingLic CarParkFree_Work           PTpass         internal \n    1.863227e+00     2.660375e+00     3.464699e+00     2.400178e+00 \n          Lisboa         Area_km2 \n    3.451852e+00     1.313708e+00 \n```\n\n\n:::\n:::\n\n\n\n\n\nA common rule of thumb is that a VIF value greater than 5 indicates a high level of multicollinearity among the predictor variables, which is potentially concerning.\n\n### Condition index\n\nCondition index is another diagnostic tool for detecting multicollinearity, with values above 10 indicating moderate multicollinearity and values above 30 indicating severe multicollinearity.\nYou will learn how to to that in the next class: [Factor analysis](factor-analysis.qmd).\n\n## Assumption 4: Independence of observations\n\nMultiple linear regression assumes that each observation in the dataset is independent.\n\nThe error (E) is independent across observations and the error variance is constant across IV\n\nThe simplest way to determine if this assumption is met is to perform a Durbin-Watson test, which is a formal statistical test that tells us whether or not the **residuals** (and thus the **observations**) exhibit autocorrelation.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndurbinWatsonTest(model)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n lag Autocorrelation D-W Statistic p-value\n   1      0.07881007      1.840798   0.132\n Alternative hypothesis: rho != 0\n```\n\n\n:::\n:::\n\n\n\n\n\n::: callout-note\nIn the Durbin-Watson test, values of the D-W Statistic vary from 0 to 4.\n\nIf the values are from 1.8 to 2.2 this means that there is **no autocorrelation** in the model.\n:::\n\n**H~0~ (null hypothesis):** There is no correlation among the residuals.\nSince p-value \\> 0.05, we do not reject the null hypothesis and we can not discard that there is autocorrelation in the model.\n\nIf the observations are not independent, you may consider to treat the observarions as a panel data.\n\n## Assumption 5: Constant Variance (Homoscedasticity)\n\nThe simplest way to determine if this assumption is met is to create a plot of standardized residuals versus predicted values.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(model)\n```\n\n::: {.cell-output-display}\n![](linear-regression_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](linear-regression_files/figure-html/unnamed-chunk-12-2.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](linear-regression_files/figure-html/unnamed-chunk-12-3.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](linear-regression_files/figure-html/unnamed-chunk-12-4.png){width=672}\n:::\n:::\n\n\n\n\n\nFor the Residuals, check the following **assumptions**:\n\n-   **Residuals vs Fitted:** This plot is used to detect non-linearity, heteroscedasticity, and outliers.\n\n-   **Normal Q-Q:** The quantile-quantile (Q-Q) plot is used to check if the disturbances follow a normal distribution\n\n-   **Scale-Location:** This plot is used to verify if the residuals are spread equally (homoscedasticity) or not (heteroscedasticity) through the sample.\n\n-   **Residuals vs Leverage:** This plot is used to detect the impact of the outliers in the model.\n    If the outliers are outside the Cook-distance, this may lead to serious problems in the model.\n\nTry analyzing the plots and check if the model meets the assumptions.\n\n## Assumption 6: Residuals are normally distributed\n\nAssess the Q-Q Residuals plot above.\nWhen the residuals clearly depart from a straight diagonal line, it indicates that they do not follow a normal distribution.\n\nUse a formal statistical test like Shapiro-Wilk or Kolmogorov-Smironov to validate those results.\n\n\n\n\n\n\n",
    "supporting": [
      "linear-regression_files/figure-html"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}